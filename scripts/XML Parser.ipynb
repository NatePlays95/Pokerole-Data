{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict \n",
    "import json\n",
    "import os\n",
    "\n",
    "pokedex_path = '../raw/XmlDump/DexEntries.json'\n",
    "pokedex_data_dir = '../Version20/Pokedex/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n"
     ]
    }
   ],
   "source": [
    "book_raw = json.loads(open(pokedex_path).read())\n",
    "len(book_raw)\n",
    "len(os.listdir(pokedex_data_dir))\n",
    "cnt = 0\n",
    "for raw in book_raw:\n",
    "    flag = False\n",
    "    for fname in os.listdir(pokedex_data_dir):\n",
    "        json_data = json.loads(open(pokedex_data_dir+'/'+fname).read())\n",
    "        n = json_data['Name']\n",
    "        if n == raw['Name']:\n",
    "            cnt+=1\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag: print(raw['Name'])\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dex Entries Merge\n",
    "\n",
    "The name of our data is the same as the book ids, so we can merge on that. (Going forward, the _id should remain the ID used in the book (IE, Form Zacian) even if we clean up those names in the Name field.)\n",
    "\n",
    "This'll need to be expanded for **updating existing values** and **to produce move lists**, because that'll automate 2.1 hopefully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_raw = json.loads(open(pokedex_path).read())\n",
    "book_keyed = {}\n",
    "for raw in book_raw:\n",
    "    book_keyed[raw['Name']] = raw\n",
    "\n",
    "for fname in os.listdir(pokedex_data_dir):\n",
    "    # fname = 'Charizard.json'\n",
    "    if '.json' not in fname: continue\n",
    "    path = pokedex_data_dir+fname\n",
    "    data = json.loads(open(path).read())\n",
    "    new = book_keyed[data['Name']]\n",
    "    if new['Name'] == 'Egg': continue\n",
    "    try:\n",
    "        data[\"DexCategory\"] = new.get('Category',\"\")\n",
    "        data['Height'] = {}\n",
    "        data['Height']['Deimeters'] = int(new['AverageHeight']['@Value'])\n",
    "        data['Height']['Meters'] = round(int(new['AverageHeight']['@Value'])*0.1, 2)\n",
    "        data['Height']['Feet'] = round(int(new['AverageHeight']['@Value'])*0.3280839895, 1)\n",
    "        data['Weight'] = {}\n",
    "        data['Weight']['Hectograms'] = int(new['AverageWeight']['@Value'])\n",
    "        data['Weight']['Kilograms'] = round(int(new['AverageWeight']['@Value'])*0.1, 2)\n",
    "        data['Weight']['Pounds'] = round(int(new['AverageWeight']['@Value'])*0.2204622622, 1)\n",
    "        data[\"DexDescription\"] = new.get('DexDescription',\"\")\n",
    "        data['Baby'] = new.get('IsBaby') == \"true\"\n",
    "        data['PrimaryEggGroup'] = new['PrimaryEggGroup']\n",
    "        data['SecondaryEggGroup'] = new['SecondaryEggGroup'] if type(new['SecondaryEggGroup']) == str else \"\"\n",
    "        \n",
    "        data['BookImageName'] = new['PrimaryImage']['@DisplayName']\n",
    "        if new.get('ShinyImage'): data['BookShinyImageName'] = new['ShinyImage']['@DisplayName']\n",
    "        \n",
    "        if new['MegaEvolutions']:\n",
    "            data['MegaEvolutions'] = []\n",
    "            extract = new['MegaEvolutions']['MegaEvolutionEntry']\n",
    "            if type(extract) == dict: extract = [extract]\n",
    "            for evo in extract:\n",
    "                data['MegaEvolutions'].append(\n",
    "                    {\"Name\":evo['TargetEvolution']['@DisplayName'], \"Item\":evo['Item']['@DisplayName']})\n",
    "    except:\n",
    "        print(\"ERROR: \"+ new['Name'])\n",
    "        print(new)\n",
    "        raise\n",
    "        # raise err\n",
    "    \n",
    "    # print(json.dumps(data))\n",
    "    # break\n",
    "    open(path,'w').write(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dem Evolution trees\n",
    "One backward entry and 0 or more forward entries\n",
    "\n",
    "Discussion about schema: https://discord.com/channels/245675629515767809/965329923256516628/1032106033277059146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, NamedTuple, Union, Set, Tuple\n",
    "evolution_tree_path = '../raw/XmlDump/EvolutionTrees.json'\n",
    "#\n",
    "evolution_tree = json.load(open(evolution_tree_path))\n",
    "#sorry, I need my type safety... Or hints at least...\n",
    "Evo_tree_entry = NamedTuple('Evo_tree_entry',\n",
    "    from_mon=str,\n",
    "    to_mon=str,\n",
    "    kind=str,\n",
    "    #todo: Parse into json after being read\n",
    "    details=str\n",
    ")\n",
    "Evo_dict = Dict[str, NamedTuple('Evo_items',\n",
    "    evo_from=Evo_tree_entry,\n",
    "    evo_to=list[Evo_tree_entry],\n",
    "    baby_item=str\n",
    ")]\n",
    "mon_to_evo_vals: Evo_dict = {}\n",
    "#collect the values\n",
    "for tree in evolution_tree:\n",
    "    #root is defined as \"Does not evolve from anything\"\n",
    "    baby_item = tree.get(\"BabyEvolutionItem\")\n",
    "    counter_part = tree.get(\"BreedCounterpart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cdd4e68c4320872200c3d463595837f7cccd19bf47d2ea25f2f136b121d292e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
